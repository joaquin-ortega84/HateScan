{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/downloaded/Dynamically Generated Hate Dataset v0.2.3.csv')\n",
=======
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/as download/Dynamically Generated Hate Dataset v0.2.3.csv')\n",
>>>>>>> main
    "df = df[df['level'] == 'original']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 124,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'label': 'HateLabel', 'text': 'TweetText'}).drop(columns=['Unnamed: 0','X1', 'split', 'round.base', 'annotator', 'round', 'acl.id.matched','type', 'level'])\n",
    "relabel = {0:2,1:1,2:0}\n",
    "\n",
    "df.replace({'HateLabel': relabel}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['target', 'acl.id'],inplace=True)"
=======
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_drop = ['none','notgiven','notargetrecorded']\n",
    "# df = df[df['target'].isin(val_drop)]"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['HateLabel'] == 'hate']\n",
    "df.replace({'HateLabel': {'hate': 2}}, inplace=True)"
=======
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbqt = ['trans','gendermin', 'gay', 'gay.wom', 'trans, lgbtq', 'gay.man', 'bis', 'gay.wom, gay.man', 'gay, gay.wom', 'trans, lgbtq', 'trans, gendermin', 'trans, gay, gay.wom, bis', 'trav, wom', 'wom, gay.man', ] # could be part of gender"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/prepped/dhg_hatelabel.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DHG Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:34,  2.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m tweet_text \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mTweetText\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[39m# Classify the tweet text\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m category \u001b[39m=\u001b[39m classify_tweet(tweet_text)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Create a new row with the classified text, category, and original HateLabel\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_row \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mTweetText\u001b[39m\u001b[39m'\u001b[39m: tweet_text, \u001b[39m'\u001b[39m\u001b[39mClassification\u001b[39m\u001b[39m'\u001b[39m: category, \u001b[39m'\u001b[39m\u001b[39mHateLabel\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mHateLabel\u001b[39m\u001b[39m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m, in \u001b[0;36mclassify_tweet\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify_tweet\u001b[39m(text):\n\u001b[0;32m----> 9\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     10\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m         prompt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mClassify the type of this tweet text: \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mtext\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mCategory:\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m         n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m         stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     category \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m category\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (26095,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lgbqt_cat \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m lgbqt]\n\u001b[1;32m      2\u001b[0m lgbqt_cat\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/ops/common.py:65\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     63\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/ops/__init__.py:370\u001b[0m, in \u001b[0;36m_comp_method_SERIES.<locals>.wrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m lvalues \u001b[39m=\u001b[39m extract_array(\u001b[39mself\u001b[39m, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    368\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 370\u001b[0m res_values \u001b[39m=\u001b[39m comparison_op(lvalues, rvalues, op)\n\u001b[1;32m    372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:224\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, (np\u001b[39m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    220\u001b[0m     \u001b[39m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[39m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[39m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lvalues) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 224\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    225\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLengths must match to compare\u001b[39m\u001b[39m\"\u001b[39m, lvalues\u001b[39m.\u001b[39mshape, rvalues\u001b[39m.\u001b[39mshape\n\u001b[1;32m    226\u001b[0m         )\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues):\n\u001b[1;32m    229\u001b[0m     \u001b[39m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     res_values \u001b[39m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (26095,), (1,))"
>>>>>>> main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import pandas as pd\n",
    "import tqdm\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Function to classify the tweet text\n",
    "def classify_tweet(text):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=f\"Classify the type of this tweet text: '{text}'\\nCategory:\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=1,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    category = response.choices[0].text.strip()\n",
    "    return category\n",
    "\n",
    "# Load your input DataFrame\n",
    "data = pd.read_csv('../data/prepped/dhg_hatelabel.csv')\n",
    "\n",
    "# Create an empty DataFrame to store the classification results\n",
    "classified_data = pd.DataFrame(columns=['TweetText', 'Classification', 'HateLabel'])\n",
    "\n",
    "for index, row in tqdm.tqdm(data.iterrows()):\n",
    "    tweet_text = row['TweetText']\n",
    "    \n",
    "    # Classify the tweet text\n",
    "    category = classify_tweet(tweet_text)\n",
    "    \n",
    "    # Create a new row with the classified text, category, and original HateLabel\n",
    "    new_row = {'TweetText': tweet_text, 'Classification': category, 'HateLabel': row['HateLabel']}\n",
    "    \n",
    "    # Append the classified row to the DataFrame\n",
    "    classified_data = classified_data.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # Save the classified data to a CSV file\n",
    "    classified_data.to_csv(\"classified_tweets.csv\", index=False)\n",
    "\n",
    "# Final save after all iterations are complete\n",
    "classified_data.to_csv(\"classified_tweets.csv\", index=False)\n"
=======
    "lgbqt_cat = df[df['target'] == lgbqt]\n",
    "lgbqt_cat"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "# Function to classify the tweet text\n",
    "# def classify_tweet(text, categories):\n",
    "#     response = openai.Completion.create(\n",
    "#         model=\"text-davinci-002\",\n",
    "#         prompt=f\"Classify the type of this tweet text: '{text}'\\nCategories: {', '.join(categories)}\\nCategory:\",\n",
    "#         temperature=0.3,\n",
    "#         max_tokens=1,\n",
    "#         n=1,\n",
    "#         stop=None\n",
    "#     )\n",
    "\n",
    "#     category = response.choices[0].text.strip()\n",
    "#     return category\n",
    "import time\n",
    "def get_topic(text):\n",
    "    categories = ['Religion', 'Gender', 'Race', 'Politics', 'Sports', 'LGQBT', 'Disability']\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                f\"Classify the type of this tweet text: '{text}'\\nCategories: {', '.join(categories)}\\nCategory:\",\n",
    "            }],\n",
    "            )\n",
    "    except:\n",
    "        time.sleep(3)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                f\"Classify the type of this tweet text: '{text}'\\nCategories: {', '.join(categories)}\\nCategory:\",\n",
    "            }],\n",
    "            )\n",
    "        \n",
    "        \n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "new =df.groupby('target').agg({'text': lambda x: list(x)[0]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [03:53<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "new['newcolumn'] = new['text'].progress_apply(get_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
=======
   "execution_count": 75,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>acl.id</th>\n",
       "      <th>X1</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>level</th>\n",
       "      <th>split</th>\n",
       "      <th>round.base</th>\n",
       "      <th>annotator</th>\n",
       "      <th>round</th>\n",
       "      <th>acl.id.matched</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>acl1</td>\n",
       "      <td>1</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>GNZuCtwed3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>acl10</td>\n",
       "      <td>2</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>GNZuCtwed3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>acl100</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>vDe7GN0NrL</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>acl1000</td>\n",
       "      <td>4</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>oemYWm1Tjg</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>acl10000</td>\n",
       "      <td>5</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>QiOKkCi7F8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>117100</td>\n",
       "      <td>acl9974</td>\n",
       "      <td>41228</td>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>original</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>GNZuCtwed3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>118100</td>\n",
       "      <td>acl11574</td>\n",
       "      <td>1752</td>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>hate</td>\n",
       "      <td>derogation</td>\n",
       "      <td>wom</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>CAgNlUizNm</td>\n",
       "      <td>2a</td>\n",
       "      <td>acl11575</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>119100</td>\n",
       "      <td>acl13446</td>\n",
       "      <td>3832</td>\n",
       "      <td>fuck covid</td>\n",
       "      <td>nothate</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>CAgNlUizNm</td>\n",
       "      <td>2a</td>\n",
       "      <td>acl13447</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>1205</td>\n",
       "      <td>acl13457</td>\n",
       "      <td>3844</td>\n",
       "      <td>This computer is garbage</td>\n",
       "      <td>nothate</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>eLGzdD8Tvb</td>\n",
       "      <td>2a</td>\n",
       "      <td>acl13458</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>121100</td>\n",
       "      <td>acl32095</td>\n",
       "      <td>24553</td>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>hate</td>\n",
       "      <td>threatening</td>\n",
       "      <td>mus</td>\n",
       "      <td>original</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>IBsVsBliwX</td>\n",
       "      <td>4a</td>\n",
       "      <td>acl32096</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26095 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    acl.id     X1  \\\n",
       "0               1      acl1      1   \n",
       "1               2     acl10      2   \n",
       "2               3    acl100      3   \n",
       "3               4   acl1000      4   \n",
       "4               5  acl10000      5   \n",
       "...           ...       ...    ...   \n",
       "41139      117100   acl9974  41228   \n",
       "41140      118100  acl11574   1752   \n",
       "41141      119100  acl13446   3832   \n",
       "41142        1205  acl13457   3844   \n",
       "41143      121100  acl32095  24553   \n",
       "\n",
       "                                                    text    label  \\\n",
       "0                                    dalits are lowlives     hate   \n",
       "1                 gay people are a burden to our society     hate   \n",
       "2                                  Arabs are not welcome     hate   \n",
       "3      I'm not saying we should actually eliminate he...     hate   \n",
       "4                           bananas are for black people     hate   \n",
       "...                                                  ...      ...   \n",
       "41139                     Indian culture is so backwards     hate   \n",
       "41140  Women don't want equality, they just want to b...     hate   \n",
       "41141                                         fuck covid  nothate   \n",
       "41142                           This computer is garbage  nothate   \n",
       "41143                 The only good Muslim is a dead one     hate   \n",
       "\n",
       "              type    target     level  split  round.base   annotator round  \\\n",
       "0         notgiven  notgiven  original  train           1  GNZuCtwed3     1   \n",
       "1         notgiven  notgiven  original  train           1  GNZuCtwed3     1   \n",
       "2         notgiven  notgiven  original  train           1  vDe7GN0NrL     1   \n",
       "3         notgiven  notgiven  original  train           1  oemYWm1Tjg     1   \n",
       "4         notgiven  notgiven  original   test           1  QiOKkCi7F8     1   \n",
       "...            ...       ...       ...    ...         ...         ...   ...   \n",
       "41139     notgiven  notgiven  original   test           1  GNZuCtwed3     1   \n",
       "41140   derogation       wom  original  train           2  CAgNlUizNm    2a   \n",
       "41141         none      none  original  train           2  CAgNlUizNm    2a   \n",
       "41142         none      none  original  train           2  eLGzdD8Tvb    2a   \n",
       "41143  threatening       mus  original  train           4  IBsVsBliwX    4a   \n",
       "\n",
       "      acl.id.matched   topic  \n",
       "0                NaN    Race  \n",
       "1                NaN    Race  \n",
       "2                NaN    Race  \n",
       "3                NaN    Race  \n",
       "4                NaN    Race  \n",
       "...              ...     ...  \n",
       "41139            NaN    Race  \n",
       "41140       acl11575  Gender  \n",
       "41141       acl13447    Race  \n",
       "41142       acl13458    Race  \n",
       "41143       acl32096    Race  \n",
       "\n",
       "[26095 rows x 14 columns]"
      ]
     },
     "execution_count": 60,
=======
      "text/plain": [
       "array(['hate'], dtype=object)"
      ]
     },
     "execution_count": 75,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "mapping = dict(zip(new['target'], new['newcolumn']))\n",
    "df['topic'] = df['target'].map(mapping)"
=======
    "df.HateLabel.unique()"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>TopicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25586</th>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25587</th>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25588</th>\n",
       "      <td>fuck covid</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25589</th>\n",
       "      <td>This computer is garbage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25590</th>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25591 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TweetText  TopicID\n",
       "0                                    dalits are lowlives        2\n",
       "1                 gay people are a burden to our society        2\n",
       "2                                  Arabs are not welcome        2\n",
       "3      I'm not saying we should actually eliminate he...        2\n",
       "4                           bananas are for black people        2\n",
       "...                                                  ...      ...\n",
       "25586                     Indian culture is so backwards        2\n",
       "25587  Women don't want equality, they just want to b...        1\n",
       "25588                                         fuck covid        2\n",
       "25589                           This computer is garbage        2\n",
       "25590                 The only good Muslim is a dead one        2\n",
       "\n",
       "[25591 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/prepped/dhg_topicID.csv')\n",
    "df"
=======
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['target', 'acl.id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['HateLabel'] == 'hate']\n",
    "df.replace({'HateLabel': {'hate': 2}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/prepped/dhg_hatelabel.csv')"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0' 'X1' 'split' 'round.base' 'annotator' 'round'\\n 'acl.id.matched' 'type' 'level'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mrename(columns\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mHateLabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mTweetText\u001b[39;49m\u001b[39m'\u001b[39;49m})\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mUnnamed: 0\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mX1\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msplit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mround.base\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mannotator\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mround\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39macl.id.matched\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlevel\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m relabel \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m:\u001b[39m0\u001b[39m}\n\u001b[1;32m      4\u001b[0m df\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39mHateLabel\u001b[39m\u001b[39m'\u001b[39m: relabel}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:4167\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4039\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4040\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4046\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4047\u001b[0m ):\n\u001b[1;32m   4048\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4049\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4050\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4165\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4168\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4169\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4170\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4171\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4172\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4173\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4174\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4175\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:3889\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   3888\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3889\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:3923\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   3922\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3923\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   3924\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{axis_name: new_axis})\n\u001b[1;32m   3926\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   3927\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/indexes/base.py:5287\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   5286\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 5287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5288\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0' 'X1' 'split' 'round.base' 'annotator' 'round'\\n 'acl.id.matched' 'type' 'level'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'label': 'HateLabel', 'text': 'TweetText'}).drop(columns=['Unnamed: 0','X1', 'split', 'round.base', 'annotator', 'round', 'acl.id.matched','type', 'level'])\n",
    "relabel = {0:2,1:1,2:0}\n",
    "\n",
    "df.replace({'HateLabel': relabel}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target' 'acl.id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39macl.id\u001b[39;49m\u001b[39m'\u001b[39;49m],inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:4167\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4039\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4040\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4046\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4047\u001b[0m ):\n\u001b[1;32m   4048\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4049\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4050\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4165\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4168\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4169\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4170\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4171\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4172\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4173\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4174\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4175\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:3889\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   3888\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3889\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:3923\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   3922\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3923\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   3924\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{axis_name: new_axis})\n\u001b[1;32m   3926\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   3927\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/indexes/base.py:5287\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   5286\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 5287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5288\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['target' 'acl.id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(columns=['target', 'acl.id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>fuck covid</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>This computer is garbage</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>Race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26095 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TweetText   topic\n",
       "0                                    dalits are lowlives    Race\n",
       "1                 gay people are a burden to our society    Race\n",
       "2                                  Arabs are not welcome    Race\n",
       "3      I'm not saying we should actually eliminate he...    Race\n",
       "4                           bananas are for black people    Race\n",
       "...                                                  ...     ...\n",
       "41139                     Indian culture is so backwards    Race\n",
       "41140  Women don't want equality, they just want to b...  Gender\n",
       "41141                                         fuck covid    Race\n",
       "41142                           This computer is garbage    Race\n",
       "41143                 The only good Muslim is a dead one    Race\n",
       "\n",
       "[26095 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['HateLabel'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = {'Religion': 0, 'Gender': 1, 'Race': 2, 'Politics': 3, 'Sports': 4, 'LGQBT': 5, 'Disability': 6}\n",
    "df.replace({'topic': relabel}, inplace=True)\n",
    "df.rename(columns={'topic': 'TopicID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cat = df[df['TopicID'].apply(lambda x: isinstance(x, int) and 0 <= x <= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    22494\n",
       "1     1744\n",
       "3      601\n",
       "0       22\n",
       "Name: TopicID, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_cat.TopicID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cat.to_csv('../data/prepped/dhg_topicID.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/prepped/dhg_openai_topic_hatelabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oldnamex</th>\n",
       "      <th>newcolumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notgiven</td>\n",
       "      <td>None/Other. The tweet text 'notgiven' does not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>None (as stated in the tweet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trav</td>\n",
       "      <td>None of the above. The tweet text 'trav' does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>N/A (The text 'for' does not fit into any of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bla</td>\n",
       "      <td>Unclassified/Not Applicable (the text 'bla' do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>bla.wom, asi.south</td>\n",
       "      <td>None of the above. It appears to be a random s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>bla, wom, hispanic, lgbtq</td>\n",
       "      <td>Race/LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>dis, for</td>\n",
       "      <td>None of the above. This tweet text consists of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>jew, mus.wom</td>\n",
       "      <td>Religion and Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>bla, asi</td>\n",
       "      <td>None of the above, it cannot be classified int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      oldnamex  \\\n",
       "0                     notgiven   \n",
       "1                         none   \n",
       "3                         trav   \n",
       "7                          for   \n",
       "8                          bla   \n",
       "..                         ...   \n",
       "292         bla.wom, asi.south   \n",
       "297  bla, wom, hispanic, lgbtq   \n",
       "298                   dis, for   \n",
       "300               jew, mus.wom   \n",
       "310                   bla, asi   \n",
       "\n",
       "                                             newcolumn  \n",
       "0    None/Other. The tweet text 'notgiven' does not...  \n",
       "1                        None (as stated in the tweet)  \n",
       "3    None of the above. The tweet text 'trav' does ...  \n",
       "7    N/A (The text 'for' does not fit into any of t...  \n",
       "8    Unclassified/Not Applicable (the text 'bla' do...  \n",
       "..                                                 ...  \n",
       "292  None of the above. It appears to be a random s...  \n",
       "297                                         Race/LGBTQ  \n",
       "298  None of the above. This tweet text consists of...  \n",
       "300                                Religion and Gender  \n",
       "310  None of the above, it cannot be classified int...  \n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['Religion', 'Gender', 'Race', 'Politics', 'Sports', 'LGQBT', 'Disability']\n",
    "\n",
    "new.loc[~new.newcolumn.isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>Africans just don't have good manners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arab</td>\n",
       "      <td>I cant believe that she think arabs are the mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arab, african</td>\n",
       "      <td>I've been living in a occupied area for 4 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arab, asi.chin</td>\n",
       "      <td>not afraid to say it I am anti-colonialism, IF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arab, ref</td>\n",
       "      <td>Refugees NOT welcome! How would they (Syrians ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>wom, mixed.race</td>\n",
       "      <td>twitter told me women can always make the best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>wom, mus.wom</td>\n",
       "      <td>I encourage all women to be clothed in full-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>wom, non.white</td>\n",
       "      <td>Now in defense of chicks, it could merely be t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>wom, pol</td>\n",
       "      <td>poles are lil bitches, women are total skanks....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>wom, wc</td>\n",
       "      <td>This bitch is an ugly person. She comes from s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target                                               text\n",
       "0            african              Africans just don't have good manners\n",
       "1               arab  I cant believe that she think arabs are the mo...\n",
       "2      arab, african  I've been living in a occupied area for 4 year...\n",
       "3     arab, asi.chin  not afraid to say it I am anti-colonialism, IF...\n",
       "4          arab, ref  Refugees NOT welcome! How would they (Syrians ...\n",
       "..               ...                                                ...\n",
       "309  wom, mixed.race  twitter told me women can always make the best...\n",
       "310     wom, mus.wom  I encourage all women to be clothed in full-bo...\n",
       "311   wom, non.white  Now in defense of chicks, it could merely be t...\n",
       "312         wom, pol  poles are lil bitches, women are total skanks....\n",
       "313          wom, wc  This bitch is an ugly person. She comes from s...\n",
       "\n",
       "[314 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>HateLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41136</th>\n",
       "      <td>Mandatory masks should be for mozzies only</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41137</th>\n",
       "      <td>Women are dishonest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14679 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TweetText  HateLabel\n",
       "0                                    dalits are lowlives          2\n",
       "1                 gay people are a burden to our society          2\n",
       "2                                  Arabs are not welcome          2\n",
       "3      I'm not saying we should actually eliminate he...          2\n",
       "4                           bananas are for black people          2\n",
       "...                                                  ...        ...\n",
       "41136         Mandatory masks should be for mozzies only          2\n",
       "41137                                Women are dishonest          2\n",
       "41139                     Indian culture is so backwards          2\n",
       "41140  Women don't want equality, they just want to b...          2\n",
       "41143                 The only good Muslim is a dead one          2\n",
       "\n",
       "[14679 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/prepped/dhg_hatelabel.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your input DataFrame\n",
    "\n",
    "# Define the list of categories\n",
    "categories = ['Religion', 'Gender', 'Race', 'Politics', 'Sports', 'LGQBT', 'Disability']\n",
    "\n",
    "# Create an empty DataFrame to store the classification results\n",
    "classified_data = pd.DataFrame(columns=['TweetText', 'Classification', 'HateLabel'])\n",
    "\n",
    "for index, row in tqdm.tqdm(data.iterrows()):\n",
    "    tweet_text = row['TweetText']\n",
    "    \n",
    "    # Classify the tweet text\n",
    "    category = classify_tweet(tweet_text, categories)\n",
    "    \n",
    "    # Create a new row with the classified text, category, and original HateLabel\n",
    "    new_row = {'TweetText': tweet_text, 'Classification': category, 'HateLabel': row['HateLabel']}\n",
    "    \n",
    "    # Append the classified row to the DataFrame\n",
    "    classified_data = classified_data.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # Save the classified data to a CSV file\n",
    "    classified_data.to_csv(\"classified_tweets.csv\", index=False)\n",
    "\n",
    "# Final save after all iterations are complete\n",
    "classified_data.to_csv(\"classified_tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
